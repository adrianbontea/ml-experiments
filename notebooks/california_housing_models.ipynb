{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "csv_path = \"D:\\Projects\\ml-experiments\\datasets\\housing\\housing.csv\"\n",
    "\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "X = data.drop(\"median_house_value\", axis=1)\n",
    "y = data.median_house_value.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the train set with scaling, inputing and one hot encoding for the non-numeric feature (ocean proximity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train.drop(\"ocean_proximity\", axis=1)\n",
    "binarizer = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next returns a 2-dimensional NumPy array (ndarray) of shape (16512,5) (16512 binary arrays of size 5 - a single 1 and rest 0 to denote a certain class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_proximity_1_hot = binarizer.fit_transform(X_train.ocean_proximity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the numeric predictors using a pipeline composed of an inputer and scaler. MinMaxScaler instantiated with default values will scale each feature between 0 and 1. Scale can be controlled using the feature_range parameter (tuple):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")), ('scaler', MinMaxScaler())])\n",
    "X_train_tr = pipeline.fit_transform(X_train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_tr is now a 2 dimensional nd array (16512,8) - Need to merge it with the binarized labels into (16512,13) shape. ocean proximity one hot vector is a 2 dimensional ndarray of shape (16512,5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tr = np.append(X_train_tr, ocean_proximity_1_hot, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_tr, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with first 5 instances from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Predictions: [189408. 290656. 250944. 147648. 165632.]\n",
      "Labels:[103000, 382100, 172600, 93400, 96500]\n"
     ]
    }
   ],
   "source": [
    "some_data = X_train_tr[:5]\n",
    "some_labels = y_train[:5]\n",
    "\n",
    "print(f\"Linear Regression Predictions: {lin_reg.predict(some_data)}\")\n",
    "print(f\"Labels:{list(some_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the error using RMSE function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE for the whole training set is: 68437.636165114\n"
     ]
    }
   ],
   "source": [
    "predictions = lin_reg.predict(X_train_tr)\n",
    "lin_mse = mean_squared_error(y_train, predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "\n",
    "print(\"Linear Regression RMSE for the whole training set is:\", lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "68437 is not great at all! (basically means a typical prediction error of $68437). The model is underfitting (too simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Predictions: [103000. 382100. 172600.  93400.  96500.]\n",
      "Labels: [103000, 382100, 172600, 93400, 96500]\n",
      "Decision Tree RMSE for the whole training set is: 0.0\n"
     ]
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train_tr, y_train)\n",
    "\n",
    "print(\"Decision Tree Predictions:\", tree_reg.predict(some_data))\n",
    "print(\"Labels:\", list(some_labels))\n",
    "\n",
    "predictions = tree_reg.predict(X_train_tr)\n",
    "lin_mse = mean_squared_error(y_train, predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "\n",
    "print(\"Decision Tree RMSE for the whole training set is:\", lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree looks perfect (0 RMSE) but it's not! It just performs perfect on the training set that it learned but won't generalize well to new data as demonstrated below(overfitting).\n",
    "\n",
    "Perform K-fold cross-validation of Decision Tree model to measure the RMSE. The algorithm splits the training set in K parts and does K training + prediction iterations each time picking one random part for evaluation and training on the other K-1. The result is K scores. The main benefit of the approach is clean predictions: on each iteration the predictor gets to predict on a subset of instances that it never saw during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Scores: [66395.02770474 68926.75670235 68203.67758163 70318.76715507\n",
      " 69184.25903717 67892.25147943 62180.54067926 69044.54017491\n",
      " 68616.18231523 68288.55396736]\n",
      "Decision Tree Mean: 67905.05567971314\n",
      "Decision Tree Standard deviation: 2135.3461008052263\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tree_reg, X_train_tr, y_train, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"Decision Tree Scores:\", rmse_scores)\n",
    "print(\"Decision Tree Mean:\", rmse_scores.mean())\n",
    "print(\"Decision Tree Standard deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test a Random Forest Regressor (works by training multiple Decision Trees on different subsets of the training set and averaging based on their predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predictions: [104560.         366453.33333333 163853.33333333  92146.66666667\n",
      "  91200.        ]\n",
      "Labels: [103000, 382100, 172600, 93400, 96500]\n",
      "Random Forest RMSE for the whole trainig set is: 19977.87442216315\n"
     ]
    }
   ],
   "source": [
    "forest_reg = RandomForestRegressor(n_estimators=15)\n",
    "forest_reg.fit(X_train_tr, y_train)\n",
    "\n",
    "print(\"Random Forest Predictions:\", forest_reg.predict(some_data))\n",
    "print(\"Labels:\", list(some_labels))\n",
    "\n",
    "predictions = forest_reg.predict(X_train_tr)\n",
    "lin_mse = mean_squared_error(y_train, predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "\n",
    "print(\"Random Forest RMSE for the whole trainig set is:\", lin_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
