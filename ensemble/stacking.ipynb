{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import time\n",
    "from mnist import *\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "training_set_path = \"D:\\\\Projects\\\\ml-experiments\\\\datasets\\\\mnist\\\\train-images-idx3-ubyte.gz\"\n",
    "train_labels_path = \"D:\\\\Projects\\\\ml-experiments\\\\datasets\\\\mnist\\\\train-labels-idx1-ubyte.gz\"\n",
    "\n",
    "f_train = gzip.open(training_set_path)\n",
    "f_train_labels = gzip.open(train_labels_path)\n",
    "\n",
    "training_set = parse_idx(f_train)\n",
    "training_labels = parse_idx(f_train_labels)\n",
    "\n",
    "training_set_tr = training_set.reshape((60000, 784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some utility function to reuse throughout experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_digit(training_set, labels, digit):\n",
    "    indexes = np.where(labels == digit)[0]\n",
    "    return training_set[indexes[np.random.randint(0, len(indexes) - 1)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking is based on a simple idea: instead of using trivial functions (such as hard voting for classification or average for regression)to aggregate the predictions of all predictors in an ensemble, why donâ€™t we train a model to perform this aggregation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The simplest stacking model involves one layer of predictors and a single aggregating predictor on top called a blender. First, the training set is split in two subsets. The first subset is used to train the predictors in the first layer. Next, the second subset is used with the predictors to make clean predictions (predictors never saw the test instances) This results in n * m predictions where n is the number of predictors in the first layer and m is the size of the second subset. Finally, these predictions and m labels for the second subset are used to train the blender(m instances of n features each). After the training phase, to make a prediction for a new instance, the ensemble will be fed the new instance starting from the bottom layer which will result in a new n-features instance which will be fed to the blender to make a final prediction. It is also possible to create multiple layers of blenders up to a single final blender.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scikit learn doesn't support Stacking out of the box but it's easy to create a custom implementation or use existing extensions such as the one in mlxtend modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier prediction is: [6]\n"
     ]
    }
   ],
   "source": [
    "classifiers = []\n",
    "\n",
    "for i in range(0, 3):\n",
    "    classifiers.append(DecisionTreeClassifier())\n",
    "\n",
    "blender = DecisionTreeClassifier() # Obviously, the predictors and the blender can be different type of classifiers\n",
    "\n",
    "stacking_clf = StackingClassifier(classifiers=classifiers, meta_classifier=blender)\n",
    "stacking_clf.fit(training_set_tr, training_labels)\n",
    "\n",
    "a_six = get_random_digit(training_set_tr, training_labels, 6)\n",
    "print(f\"StackingClassifier prediction is: {stacking_clf.predict([a_six])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
